### ADR 3. Push notification

## Status
Approved

## Context
MonitorMe software must also analyze each patientâ€™s vital signs and alert a medical professional if it detects an issue (e.g., decrease in oxygen level) or reaches a preset threshold (e.g., temperature has reached 104 degrees F).

## Decision
Use Apache Spark. Apache Spark is an open-source unified analytics engine for large-scale data processing.

## Consequences
 
### Positive
*** Speed:** Apache Spark is known for its fast processing speeds, especially for batch and stream processing tasks. It utilizes in-memory computing and optimized query execution plans, making it well-suited for analyzing large volumes of healthcare data quickly.

*** Scalability:** Spark's distributed computing architecture enables horizontal scalability, allowing it to scale seamlessly to handle growing datasets and workloads. This scalability is crucial for processing the massive amounts of healthcare data generated from sources like electronic health records (EHRs), medical imaging, and wearable devices.

*** Unified Analytics:** Spark provides a unified analytics engine with support for various data processing tasks, including batch processing, real-time stream processing, machine learning, and graph processing. This versatility allows healthcare organizations to perform a wide range of analytics tasks using a single framework.

*** Ease of Use:** Spark offers high-level APIs in programming languages like Scala, Java, Python, and R, making it accessible to developers and data scientists with different skill sets. Additionally, Spark's rich ecosystem includes libraries like Spark SQL, MLlib, GraphX, and Spark Streaming, which simplify common analytics tasks.

*** Integration:** Spark integrates seamlessly with other big data technologies and frameworks commonly used in healthcare environments, such as Hadoop Distributed File System (HDFS), Apache HBase, Apache Hive, and Apache Kafka. This facilitates data ingestion, storage, and interoperability across the healthcare data ecosystem.

### Negative
*** Complexity:** Spark can be complex to configure, deploy, and manage, especially in distributed environments. Setting up Spark clusters, optimizing performance, and troubleshooting issues require expertise in distributed systems and big data technologies.

*** Resource Intensiveness:** Spark's in-memory computing model consumes significant memory resources, especially when processing large datasets or running complex analytics jobs. This can lead to high infrastructure costs and resource contention in shared environments.

*** Learning Curve:** While Spark's high-level APIs simplify programming and analytics tasks, mastering the full capabilities of Spark and its ecosystem may require time and effort, particularly for users new to distributed computing and big data concepts.

*** Overhead:** Spark introduces overhead for tasks such as data serialization, network communication, and fault tolerance mechanisms, which can impact performance, especially for short-running jobs or latency-sensitive applications.

*** Real-time Processing Limitations:** While Spark Streaming enables real-time stream processing, it may not provide the same low-latency guarantees as specialized stream processing frameworks like Apache Flink or Apache Kafka Streams. Organizations requiring ultra-low latency real-time analytics may need to evaluate alternative solutions.